{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Quick introduction to jupyter notebooks**\n",
    "* Each cell in this notebook contains either code or text.\n",
    "* You can run a cell by pressing Ctrl-Enter, or run and advance to the next cell with Shift-Enter.\n",
    "* Code cells will print their output, including images, below the cell. Running it again deletes the previous output, so be careful if you want to save some results.\n",
    "* You don't have to rerun all cells to test changes, just rerun the cell you have made changes to. Some exceptions might apply, for example if you overwrite variables from previous cells, but in general this will work.\n",
    "* If all else fails, use the \"Kernel\" menu and select \"Restart Kernel and Clear All Output\". You can also use this menu to run all cells.\n",
    "* A useful debug tool is the console. You can right-click anywhere in the notebook and select \"New console for notebook\". This opens a python console which shares the environment with the notebook, which let's you easily print variables or test commands.\n",
    "\n",
    "### **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules when changed\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# Plot figures \"inline\" with other output\n",
    "%matplotlib inline\n",
    "\n",
    "# Import modules, classes, functions\n",
    "from datetime import timedelta\n",
    "from time import perf_counter as tic\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils import plotDatasets, loadDataset, splitData, splitDataBins, getCVSplit, plotResultsCV, plotResultsDots, plotConfusionMatrixOCR\n",
    "from evalFunctions import calcConfusionMatrix, calcAccuracy, calcAccuracyCM\n",
    "\n",
    "# Configure nice figures\n",
    "plt.rcParams['figure.facecolor']='white'\n",
    "plt.rcParams['figure.figsize']=(8,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***! IMPORTANT NOTE !***\n",
    "\n",
    "Your implementation should only use the `numpy` (`np`) module. The `numpy` module provides all the functionality you need for this assignment and makes it easier debuging your code. No other modules, e.g. `scikit-learn` or `scipy` among others, are allowed and solutions using modules other than `numpy` will be sent for re-submission. You can find everything you need about `numpy` in the official [documentation](https://numpy.org/doc/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Introduction**\n",
    "\n",
    "The focus of this assignment is **supervised learning**. In particular, you will apply several machine learning algorithms to solve classification tasks. Throughout the three notebooks that consistute this assignment you will implement a kNN classifier, as well as single-layer and two-layer neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.1 Data**\n",
    "\n",
    "Let's start by examining the datasets used in this assignments. Run the following cell to visualize the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDatasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, datasets 1, 2 and 3 are point clouds with various shapes and number of classes, while dataset 4 consists of 8x8 pixel images of handwritten digits (these are stored as 64-length vectors). Each dataset in this assignment consists of three variables:\n",
    "- `X` contains the input features for the data samples.\n",
    "- `D` contains neural network target output values for the data samples. These are not used with kNN, and will be explained in the other notebooks in this assignment.\n",
    "- `L` contains the class labels for the data samples.\n",
    "\n",
    "Use the code in the next cell to load and examine all four datasets. Note that this assignment follows the convention that data samples are in the rows of a matrix, while features are in the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetNr = 1\n",
    "X, D, L = loadDataset(datasetNr)\n",
    "\n",
    "print(f\"X has shape {X.shape}\")\n",
    "print(f\"D has shape {D.shape}\")\n",
    "print(f\"L has shape {L.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<span style=\"color:red\">Question 1:</span>**\n",
    "Describe all four datasets used in this assignment from a machine learning perspective:\n",
    "- What does the dataset represent? What kind of data is it made of, and what can you tell about its arrangement?\n",
    "- How many samples are in each dataset? How many features do they have?\n",
    "- How many classes does each dataset have? What do they represent?\n",
    "- Will the dataset require a linear or nonlinear classifier? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<span style=\"color:green\">Answer:</span>**\n",
    "\n",
    "\\[ Your answers here \\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **2. The kNN classifier**\n",
    "\n",
    "k-nearest neighbors (kNN) is a relatively simple classification algorithm, that nevertheless can be quite effective. It is a nonlinear classifier where each new sample is assigned the class that most commonly appears among its neighbors in the training data, i.e. those training samples with the shortest distance to it. Distances in kNN can actually be defined in many different ways based on the application, but here we will use the most common Euclidean distance. The number of neighboring samples to consider, called k, is the only parameter of the algorithm. Depending on the specific properties of the problem, different values of k might give optimal results.\n",
    "\n",
    "Unlike other types of classifiers, such as support vector machines and neural networks, kNN does not have any trainable parameters, and thus requires no training. It does, however, require a training dataset, which is effectively \"memorized\", and used as reference to classify all future data. This has the advantage of no training time, but results in slow inference times, which are proportional to the amount of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.1 Implement the kNN algorithm**\n",
    "\n",
    "The `kNN` function takes as input arguments the set of samples to be classified `X`, the number of neighbors to consider `k`, an the training samples `XTrain` and labels `LTrain`. There are different ways to implement the kNN algorithm, but we recommend you to follow these steps:\n",
    "\n",
    "1. Calculate the Euclidean distances between every point in `X` and every point in `XTrain` and save them in a large matrix. Recall that the Eucliden distance between two $N$-dimensional points $\\mathbf{x}$ and $\\mathbf{y}$ is given as\n",
    "\n",
    "$$ \\large d = \\sqrt{\\sum_{i=1}^N (x_i - y_i)^2} .$$\n",
    "\n",
    "Your implementation should not assume any specific number of features in the data, but should work for data of any number of features.\n",
    "\n",
    "2. From each row of the matrix, select the `k` points with the smallest distance.\n",
    "\n",
    "3. Find the class that appears most often among the `k` closest points and assign it to the corresponding point in `X`.\n",
    "\n",
    "4. Sometimes there is a draw between two neighboring classes. Detect this and implement a strategy for choosing the class.\n",
    "\n",
    "Keep in mind that, as was said previously, classifying data with kNN can be time-consuming, and an efficient implementation can really save you some time in the long run (especially once we implement cross-validation in section 3). Because of this, it is recommended that you try to avoid loops as much as possible, and instead take full advantage of `numpy`'s capacity for operating directly on arrays and [broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html) arrays. Some loops will likely be necessary, but you will see performance gains if you try to minimize their use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN(X, k, XTrain, LTrain):\n",
    "    \"\"\" KNN\n",
    "    Your implementation of the kNN algorithm.\n",
    "\n",
    "    Args:\n",
    "        X (array): Samples to be classified.\n",
    "        k (int): Number of neighbors.\n",
    "        XTrain (array): Training samples.\n",
    "        LTrain (array): Correct labels of each sample.\n",
    "\n",
    "    Returns:\n",
    "        LPred (array): Predicted labels for each sample.\n",
    "    \"\"\"\n",
    "\n",
    "    classes = np.unique(LTrain)\n",
    "    nClasses = classes.shape[0]\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # === Your code here =========================\n",
    "    # --------------------------------------------\n",
    "    \n",
    "    # Calculate all the distances between X and XTrain\n",
    "    ...\n",
    "        \n",
    "    # Sort distances and find k closest labels\n",
    "    ...\n",
    "\n",
    "    # Find the most common label, store in LPred\n",
    "    ...\n",
    "        \n",
    "    # ============================================\n",
    "    \n",
    "    return LPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.2 Test it on some data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test your implementation, you will first need to split the available data into training and test sets. You can then classify the test data using the training data as reference. Use the `splitData` function for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and load dataset\n",
    "datasetNr = 1\n",
    "X, D, L = loadDataset(datasetNr)\n",
    "\n",
    "# Split data into training set (85%) and test set (15%)\n",
    "XTrain, _, LTrain, XTest, _, LTest = splitData(X, D, L, 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a value for `k` and classify the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of neighbors\n",
    "k = 1\n",
    "\n",
    "# Classify training data\n",
    "LPredTrain = kNN(XTrain, k, XTrain, LTrain)\n",
    "# Classify test data\n",
    "LPredTest  = kNN(XTest , k, XTrain, LTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and print the training and test accuracies as well as the confusion matrix for the test data. For this to work, you first need to open the file `evalFunctions.py` and implement the functions `calcAccuracy`, `calcConfusionMatrix`, and `calcAccuracyCM`, based on the function descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the training and test accuracy\n",
    "accTrain = calcAccuracy(LPredTrain, LTrain)\n",
    "accTest = calcAccuracy(LPredTest, LTest)\n",
    "print(f\"Train accuracy: {accTrain:.4f}\")\n",
    "print(f\"Test accuracy: {accTest:.4f}\")\n",
    "\n",
    "# Calculate confunsion matrix of test data\n",
    "confMatrix = calcConfusionMatrix(LPredTest, LTest)\n",
    "print()\n",
    "print(\"Test data confusion matrix:\")\n",
    "print(confMatrix)\n",
    "\n",
    "accTestCM = calcAccuracyCM(confMatrix)\n",
    "print()\n",
    "print(f\"Test accuracy from CM: {accTestCM:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use some plotting functions to examine the classified training and test data, as well as the decision boundaries that separate the various classes. We will use these types of visualizations for all three classifier types.\n",
    "\n",
    "For datasets 1-3 you will see classification results for the training and test data, where correctly classified samples appear in green and incorrectly classified samples appear in red. The backgrounds of these plots show in grayscale colors the different regions of the feature space which are assigned each class by the classifier. This is especially useful in order to examine the shape of the decision boundaries.\n",
    "\n",
    "For the dataset 4 you will see a plot that shows examples of each type of correct and incorrect classification as given by the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if datasetNr < 4:\n",
    "    plotResultsDots(XTrain, LTrain, LPredTrain, XTest, LTest, LPredTest, lambda X: kNN(X, k, XTrain, LTrain))\n",
    "else:\n",
    "    plotConfusionMatrixOCR(XTest, LTest, LPredTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<span style=\"color:red\">Question 2:</span>**\n",
    "- Describe how your kNN implementation works, step by step.\n",
    "- Describe the way in which your implementation handles ties in the neighbor classes, that is, situations in which several classes are equally common among the neighbors of a point. For example, `k=4` and the classes of the neighbors are `[0,0,1,1]`, or `k=5` and the classes are `[1,1,2,3,3]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<span style=\"color:green\">Answer:</span>**\n",
    "\n",
    "\\[ Your answers here \\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.3 Try kNN on all datasets**\n",
    "\n",
    "Once you have made sure that your kNN implementation works correctly, we can define a function that performs all of the previous steps: it loads data, trains and evaluates a kNN on a specific dataset using your own kNN implementation, and prints the results. You can use it to experiment with applying your kNN implementation on all the datasets. Try experimenting with different values of `k` and note especially the effect that it has on the decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runkNNOnDataset(datasetNr, testSplit, k):\n",
    "    X, D, L = loadDataset(datasetNr)\n",
    "    XTrain, _, LTrain, XTest, _, LTest = splitData(X, D, L, testSplit)\n",
    "\n",
    "    LPredTrain = kNN(XTrain, k, XTrain, LTrain)\n",
    "    LPredTest = kNN(XTest, k, XTrain, LTrain)\n",
    "    \n",
    "    accTrain = calcAccuracy(LPredTrain, LTrain)\n",
    "    accTest = calcAccuracy(LPredTest, LTest)\n",
    "    confMatrix = calcConfusionMatrix(LPredTest, LTest)\n",
    "    \n",
    "    print(f'Train accuracy: {accTrain:.4f}')\n",
    "    print(f'Test accuracy: {accTest:.4f}')\n",
    "    print(\"Test data confusion matrix:\")\n",
    "    print(confMatrix)\n",
    "\n",
    "    if datasetNr < 4:\n",
    "        plotResultsDots(XTrain, LTrain, LPredTrain, XTest, LTest, LPredTest, lambda X: kNN(X, k, XTrain, LTrain))\n",
    "    else:\n",
    "        plotConfusionMatrixOCR(XTest, LTest, LPredTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runkNNOnDataset(1, testSplit=0.15, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runkNNOnDataset(2, testSplit=0.15, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runkNNOnDataset(3, testSplit=0.15, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runkNNOnDataset(4, testSplit=0.75, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Cross-validation**\n",
    "\n",
    "As mentioned previously, different values of `k` might work better or worse for each dataset. However, in order to establish which value is best for each dataset it is not enough to run kNN once for each `k` and select the one that gives the highest accuracy. This approach would not take into account the variations in performance that result from the random splitting of training and test data. Results obtained in this way will not reflect the performance that can be expected when the algorithm is applied on new data.\n",
    "\n",
    "In order to thoroughly test which value of `k` is best we can resort to cross-validation methods, which rely on repeatedly testing the model on different splits of the data in order to assess its generalization performance. In particular, we will focus on n-fold cross-validation. In this method, we will first reserve a portion of the data for testing, `XTest`, which we will not touch until the very end, and use the remaining data `XTrain` for cross-validation. `XTrain` will again be split into `N` bins, which corresponds with the number of times that the kNN algorithm will be run for each value of `k`. For each iteration, one bin is used as validation data `XValCV`, and all the remaining bins are combined and used as training data `XTrainCV`. This will result in `N` accuracies for each value of `k`, which we will average to obtain the **average cross-validation accuracy**, which is the relevant metric for determining the optimal `k`. The higher the value of `N`, the more precise will be our determination of the accuracy of different values of `k`. This picture illustrates 3-fold cross validation for one value of `k`.\n",
    "\n",
    "![](NotebookMaterial/CrossValidation.png)\n",
    "\n",
    "After determining the value of `k` that gives the highest accuracy, we will use it to classify `XTest` using all of `XTrain` as reference data. This will give as the **test accuracy** of our model, and is the definitive metric representing its performance.\n",
    "\n",
    "Start by splitting the available data into training and test `splitData` function as before. Then, use the function `splitDataBins` to further split the training data into `N` bins. Finally, use the funciton `getCVSplit` to combine the data bins into `XTrainCV` and `XValCV`. This function takes in the degree of cross validation `N` and the current iteration of the cross validation `i`, indicating which bin will be used for the validation data (note that this is zero-indexed). Three-fold cross-validation should be a minimum, but do not be afraid to try using more bins, e.g. 50-100, as the resulting inference time increases less than linearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and load dataset\n",
    "datasetNr = 1\n",
    "X, D, L = loadDataset(datasetNr)\n",
    "\n",
    "# Split data into training and test sets\n",
    "XTrain, _, LTrain, XTest, _, LTest = splitData(X, D, L, 0.15)\n",
    "\n",
    "# Select the number of bins to split the data\n",
    "nBins = 50\n",
    "\n",
    "# Split data into bins based on the settings above\n",
    "# The outputs are lists of length nBins, where each item is a data array. Try printing for example XBins[0].shape.\n",
    "XBins, _, LBins = splitDataBins(XTrain, None, LTrain, nBins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish the implementation of the `crossValidation` function, which needs to take a maximum value of `k` and the cross validation bins and return a matrix containing the cross-validation accuracies obtained for different values of `k` and combinations of bins used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValiation(kMax, XBins, LBins):\n",
    "    \"\"\"Performs cross-validation using kNN\n",
    "\n",
    "    Args:\n",
    "        kMax (int): Maximum value of k to test. Values used will be [1-kMax].\n",
    "        XBins (list of arrays): Training+validation data samples.\n",
    "        LBins (list of arrays): Training+validation data labels.\n",
    "\n",
    "    Returns:\n",
    "        meanAccs (array): Cross-validation accuracies. Bins are in the rows, and\n",
    "            values of k in the columns.\n",
    "        kBest (int): Optimal value of k based on cross validation results.\n",
    "    \"\"\"\n",
    "\n",
    "    nBins = len(XBins)\n",
    "    accs = np.zeros((nBins, kMax))\n",
    "\n",
    "    # This is used to show the progress\n",
    "    timeStart = tic()\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # === Your code here =========================\n",
    "    # --------------------------------------------\n",
    "    \n",
    "    for ???\n",
    "\n",
    "        # Use getCVSplit to combine bins for training and validation data\n",
    "        ...\n",
    "        \n",
    "        for ???\n",
    "\n",
    "            # Classify validation data using kNN\n",
    "            ...\n",
    "            \n",
    "            # ... and store resulting accuracy in the accs matrix\n",
    "            ...\n",
    "            \n",
    "            # Print progress and remaining time\n",
    "            timeLeft = round((tic()-timeStart)*( nBins*kMax / (b*kMax + k + 1) - 1))\n",
    "            etaStr = str(timedelta(seconds=timeLeft))\n",
    "            print(f\"b: {b+1:2}, k: {k+1:2}, ETA: {etaStr}    \", end=\"\\r\")\n",
    "    \n",
    "    # Compute the mean cross validation accuracy for each k\n",
    "    meanAccs = ???\n",
    "    \n",
    "    # And find the best k\n",
    "    kBest    = ???\n",
    "    \n",
    "    # ============================================\n",
    "    \n",
    "    return meanAccs, kBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your cross-validation implementation and look at the resulting performance plot. This shows the average cross-validation accuracy for all the values of `k` tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanAccs, kBest = crossValiation(30, XBins, LBins)\n",
    "plotResultsCV(meanAccs, kBest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After selecting the optimal value of `k` using cross-validation, use this value to classify `XTest` using the data in `XTrain` as reference to obtain the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LPredTest = kNN(XTest, kBest, XTrain, LTrain)\n",
    "\n",
    "confMatrix = calcConfusionMatrix(LPredTest, LTest)\n",
    "acc = calcAccuracy(LPredTest, LTest)\n",
    "\n",
    "print(f\"Test accuracy: {acc:.4f}\")\n",
    "print(\"Test data confusion matrix:\")\n",
    "print(confMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<span style=\"color:red\">Question 3:</span>**\n",
    "- Describe how you implemented cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<span style=\"color:green\">Answer:</span>**\n",
    "\n",
    "\\[ Your answers here \\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **4. Cross validation for all datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we define a single function that performs all of the previous cross-validation for a given dataset and shows the results. Use it to perform cross-validation on all four datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runkNNCrossValidationOnDataset(datasetNr, testSplit, nBins, kMax):\n",
    "    X, D, L = loadDataset(datasetNr)\n",
    "    XTrain, _, LTrain, XTest, _, LTest = splitData(X, D, L, testSplit)\n",
    "    XBins, _, LBins = splitDataBins(XTrain, None, LTrain, nBins)\n",
    "\n",
    "    meanAccs, kBest = crossValiation(kMax, XBins, LBins)\n",
    "    plotResultsCV(meanAccs, kBest)\n",
    "\n",
    "    LPredTrain = kNN(XTrain, kBest, XTrain, LTrain)\n",
    "    LPredTest = kNN(XTest, kBest, XTrain, LTrain)\n",
    "    confMatrix = calcConfusionMatrix(LPredTest, LTest)\n",
    "    accTest = calcAccuracy(LPredTest, LTest)\n",
    "\n",
    "    print(f'Test accuracy: {accTest:.4f}')\n",
    "    print(\"Test data confusion matrix:\")\n",
    "    print(confMatrix)\n",
    "\n",
    "    if datasetNr < 4:\n",
    "        plotResultsDots(XTrain, LTrain, LPredTrain, XTest, LTest, LPredTest, lambda X: kNN(X, kBest, XTrain, LTrain))\n",
    "    else:\n",
    "        plotConfusionMatrixOCR(XTest, LTest, LPredTest)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runkNNCrossValidationOnDataset(1, testSplit=0.15, nBins=20, kMax=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runkNNCrossValidationOnDataset(2, testSplit=0.15, nBins=20, kMax=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runkNNCrossValidationOnDataset(3, testSplit=0.15, nBins=20, kMax=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runkNNCrossValidationOnDataset(4, testSplit=0.15, nBins=20, kMax=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<span style=\"color:red\">Question 4:</span>**\n",
    "- Comment on the results for each dataset. What is the optimal k, and are those results reasonable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<span style=\"color:green\">Answer:</span>**\n",
    "\n",
    "\\[ Your answers here \\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **5. Optional task**\n",
    "\n",
    "In section 2 in this notebook, where you first implemented the kNN algorithm, we said that \"some loops will be necessary\" in the implementation. *This is actually not true*. By rewriting the computation of the Euclidean distance in a clever way, and using the full capabilities of numpy broadcasting, it is possible to compute the distance matrix without a single loop. This solution is incredibly fast and therefore enables high degree cross validation over many values of k. Your optional task is to rewrite your implementation to have no loops, and to rerun the cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<span style=\"color:red\">Question 5:</span>**\n",
    "- How much faster is the new implementation? You can time the execution of a code cell by putting the magic command (yes, that is the official name) `%%timeit -n1 -r1` on the first row of the cell. Note that the double percentages are part of the command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<span style=\"color:green\">Answer:</span>**\n",
    "\n",
    "\\[ Your answers here \\]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2218871c41807e453fd4062f3c97a84097e40ee8d6d24bb40af7b26f3abea9d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd50aace418a96e8a4fe691a4d2292bd7058ca4eeebcf0b6e2084f539c4e7b28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
